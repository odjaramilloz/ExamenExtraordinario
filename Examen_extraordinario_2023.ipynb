{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325bc162",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: left; margin: 30px 15px 15px 15px;\" src=\"https://www.lupacity.com/wp-content/uploads/2015/05/iteso.jpg\" width=\"400\" height=\"300\" /> \n",
    "\n",
    "\n",
    "# EXAMEN EXTRAORDINARIO - 2023\n",
    "# MODELO NO LINEAL PARA PRONÓSTICOS\n",
    "\n",
    "## Nombre:\n",
    "\n",
    "## Fecha: 1 de Agosto del 2023\n",
    "\n",
    "## Por: Oscar David Jaramillo Z."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829823e1",
   "metadata": {},
   "source": [
    "# Parte 1: Modelos Lineales para Series de Tiempo Univariadas (Puntuación total: 30 puntos)\n",
    "Para este primer enunciado se utilizará la base de datos adjuntada llamada [`Demanda_historica.csv`](https://drive.google.com/file/d/1YuA3EN_cfa9LlFrI0xxMmJMYxXqegkms/view?usp=sharing). El contexto de este dataset es el siguiente:\n",
    "> El conjunto de datos contiene la demanda histórica de productos de una empresa de fabricación con presencia en todo el mundo. La compañía ofrece miles de productos dentro de docenas de categorías de productos. Hay cuatro almacenes centrales para enviar productos dentro de la región de la que es responsable. Dado que los productos se fabrican en diferentes lugares de todo el mundo, normalmente lleva más de un mes enviar productos por mar a diferentes almacenes centrales. Si se pueden lograr pronósticos para cada producto en una central diferente con una precisión razonable para la demanda mensual de un mes tras otro, sería beneficioso para la empresa de múltiples maneras\n",
    "\n",
    "1) Realizar el EDA correspondiente de la serie de tiempo suministrada (realizar los análisis estadísticos correspondientes en base a la información suministrada, explique todos los análisis y consideraciones realizadas). Además, análise los patrones por día de la semana y por estación (reporte los insights encontrados y/o gráficas que sustenten tu respuesta). Finalmente, hacer un gráfico de la serie de tiempo donde el eje x corresponda a las fechas. Antes de esto asegúrese de que la serie de tiempo no tenga NAs y Outliers y de haber dividido en train y en test (75 y 25). Realice las transformaciones y/o escalamientos que considere pertinentes (justifique sus análisis) (20 puntos).\n",
    "2) Analizar la serie de tiempo (La de train) y describir sus características principales (estacionariedad, estacionalidad, tendencia y autocorrelación). Generar los respectivos gráficos o test donde pueda sustentar sus conclusiones (20 puntos).\n",
    "3) De acuerdo con las características anteriores ¿Qué modelo cree usted que se puede acomodar bien a los datos (train) y por qué? Pruebe al menos 15 modelos distintos tipo SARIMA para los datos que concuerden con el inciso 2 (20 puntos).\n",
    "4) Escoger el mejor modelo entre los anteriores y hacer un análisis de los residuos de éste. Que puede decir de éstos residuos? (incluir al menos un gráfico o una prueba de hipótesis de ruido blanco) (20 puntos)\n",
    "5) Hacer un pronóstico de la misma longitud del test con el modelo que eligió en el inciso 3. Recuerde que este forecast deberá ir incluyendo en cada nuevo paso de pronóstico el valor anterior del dato de test. Por ejemplo, si el conjunto de test tiene 10 muestras, el primer forecast sólo incluye estimaciones del modelo entrenado con datos de train. Para la segunda predicción, se agrega a los datos de entrenamiento el primer valor del conjunto de test, se entrena el modelo con esos nuevos datos y se genera la predicción. Este proceso continua sucesivamente en cada paso de predicción. Agregue un gráfico que muestre claramente los datos de train, test y predicción (20 puntos).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ebc201",
   "metadata": {},
   "source": [
    "# Parte 2. Series de Tiempo con Redes Neuronales (Puntuación total: 35 puntos)\n",
    "Para este segundo enunciado se tendrán el dataset `Clima_Madrid.csv`. Acerca del conjunto de datos esta es la información que posee: \n",
    "\n",
    "> 27024 entradas de la estación meteorológica de Moratalaz en Madrid, entre enero de 2019 y enero de 2022 con estas variables:\n",
    "> - temperatura (°C)\n",
    "> - velocidad del viento (m/s)\n",
    "> - dirección del viento (en grados)\n",
    "> - humedad (%)\n",
    "> - presión barométrica (mb)\n",
    "> - radiación solar (W/m^2)\n",
    "> - precipitación (l/m^2)\n",
    ">\n",
    "> El objetivo es predecir la temperatura usando todo el conjunto de variables suministradas.\n",
    "\n",
    "En esta parte del examen, se enfrentarán a un conjunto de datos de series de tiempo multivariadas. Deberán diseñar y entrenar modelos MLP, LSTM, CNN y CNN-LSTM para el pronóstico de estas series de tiempo.\n",
    "\n",
    "a). Análisis y Preprocesamiento de Datos (30 puntos)\n",
    "\n",
    "1. Cargue los datos y realice un análisis exploratorio (10 puntos).\n",
    "2. Identifique posibles relaciones y patrones entre las variables (10 puntos).\n",
    "3. Preprocese los datos para que sean adecuados para el entrenamiento de los modelos (10 puntos).\n",
    "\n",
    "Justifique su análisis y procedimientos.\n",
    "\n",
    "b). Modelos MLP, LSTM, CNN y CNN-LSTM (70 puntos)\n",
    "\n",
    "4. Diseñe y entrene un modelo MLP para el pronóstico de la serie de tiempo multivariada (10 puntos).\n",
    "4. Diseñe y entrene un modelo LSTM para el pronóstico de la serie de tiempo multivariada (10 puntos).\n",
    "4. Diseñe y entrene un modelo CNN para el pronóstico de la serie de tiempo multivariada (10 puntos).\n",
    "4. Diseñe y entrene un modelo CNN-LSTM para el pronóstico de la serie de tiempo multivariada (10 puntos).\n",
    "4. Compare y analice los resultados de los diferentes modelos (10 puntos).\n",
    "(Pruebe al menos 3 estructuras distintas por cada modelo. Discuta sus resultados y explique cómo podría mejorar el rendimiento de tu modelo.)\n",
    "\n",
    "9. Evalúe el modelo en el conjunto de prueba y mide su precisión mediante la comparación del pronóstico con los valores reales. Recuerde que si alguna tranformación fue realizada debe volver los datos a su valor real para poder compararlos adecuadamente (10 puntos).\n",
    "10. En base al modelo que obtuvo mejor performance, use Optuna para ajustar los hiperparámetros del modelo para obtener una precisión óptima. Evalúe el modelo en un conjunto de prueba y mida su precisión mediante la comparación del pronóstico con los valores reales (10 puntos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7968f3",
   "metadata": {},
   "source": [
    "# Parte 3: Clasificación de Series de Tiempo (Puntuación total: 35 puntos)\n",
    "Para este tercer enunciado se usará el dataset usado en la competencia CareerCon 2019. Acerca del conjunto de datos usados en, el contexto es el siguiente:\n",
    "> **La competencia**\n",
    "> En esta competencia, se pretende ayudar a los robots a reconocer la superficie del piso sobre la que están parados utilizando los datos recopilados de las Unidades de medición inercial (sensores IMU).\n",
    ">\n",
    "> Se han recopilado datos del sensor IMU mientras conducíamos un pequeño robot móvil sobre diferentes superficies de suelo en las instalaciones de la universidad. La tarea es predecir en cuál de los nueve tipos de suelo (alfombra, baldosas, hormigón) se encuentra el robot utilizando datos de sensores como la aceleración y la velocidad. Si tiene éxito, ayudará a mejorar la navegación de los robots sin asistencia a través de muchas superficies diferentes, para que no se caigan en el trabajo.\n",
    ">\n",
    "> El conjunto de datos contiene datos preprocesados de la competencia CareerCon 2019. La principal diferencia con el conjunto de datos original es que no incluye columnas de cuaterniones sino diferencias de ángulos de Euler. Además, los datos se normalizaron para prepararlos para el entrenamiento de modelos de Deep Learning.\n",
    ">\n",
    "> **Contenido**\n",
    "> Hay tres matrices NumPy.\n",
    "> - feat.npy con entrenamiento normalizado y datos de prueba\n",
    "> - feat_fft.npy con los mismos datos pero procesados con la llamada np.fft.rfft y luego también normalizados\n",
    "> - target.npy con etiquetas de entrenamiento y etiquetas cero ficticias para los datos de prueba concatenados en una sola matriz\n",
    "\n",
    "> Tenga en cuenta que las primeras 3810 filas de cada matriz pertenecen al conjunto de entrenamiento y el resto son datos de prueba.\n",
    "> Los datos preprocesados se encuentran en el siguiente [link](https://www.kaggle.com/datasets/purplejester/career-con-2019-preprocessed-data).\n",
    "\n",
    "En esta parte del examen, el objetivo es clasificar los nueve tipos de suelo utilizando modelos MLP, LSTM, CNN y algoritmos de machine learning.\n",
    "\n",
    "a). Análisis y Preprocesamiento de Datos (20 puntos)\n",
    "\n",
    "1. Cargue los datos y realice un análisis exploratorio (10 puntos).\n",
    "2. Preprocese los datos para que sean adecuados para el entrenamiento de los modelos de clasificación (10 puntos).\n",
    "\n",
    "b). Modelos MLP, LSTM, CNN y Algoritmos de Machine Learning (80 puntos)\n",
    "\n",
    "3. Diseña modelos de clasificación utilizando algoritmos de machine learning, utiliza al menos 6 algoritmos distintos. Explica los pasos que seguirías para entrenar y validar el modelo y discute cómo podrías mejorar la precisión del modelo (15 puntos).\n",
    "4. Utilizando las mismas señales preprocesadas, diseña un modelo de clasificación utilizando una red neuronal convolucional (CNN). Diseña al menos 3 estructuras distintas y selecciona aquella que arroje mejores resultados. Recuerda las diversas estructuras estudiadas en clase. Explica los pasos que seguirías para entrenar y validar el modelo y discute cómo podrías mejorar la precisión del modelo (15 puntos).\n",
    "4. Diseña un modelo de clasificación utilizando una red neuronal LSTM. Explica los pasos que seguirías para entrenar y validar el modelo y discute cómo podrías mejorar la precisión del modelo (15 puntos).\n",
    "4. Diseña un modelo de clasificación utilizando una red neuronal CNN-LSTM y ConvLSTM. Explica los pasos que seguirías para entrenar y validar el modelo y discute cómo podrías mejorar la precisión del modelo (15 puntos).\n",
    "4. Compara el rendimiento de los diferentes modelos de clasificación multiclase utilizando diferentes métricas de evaluación. Usa métricas como precisión, recall y F1-score. ¿Cuál de los modelos ofrece la mejor precisión? ¿Hay diferencias significativas en términos de rendimiento y complejidad computacional entre los modelos? (10 puntos)\n",
    "4. En base al modelo con mejores métricas encontrado en el ejercicio anterior, realiza un optimización de hiperparámetros con el paquete `optuna`. La métrica que se intentará maximizar es el score $F_1$ (10 puntos).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67fb46c",
   "metadata": {},
   "source": [
    "### Parámetros de entrega\n",
    "La entrega de este examen se realizará a través de un link en github del cuaderno de python correspondiente. La hora de entrega es a más tardar a las 23:59 del 3 de Agosto. Se debe de enviar un correo con el link de la solución al correo odjaramilloz@iteso.mx."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e798c6a2",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Oscar David Jaramillo Zuluaga.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
